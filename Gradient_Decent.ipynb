{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3644509-78ca-4ae4-8118-61be9ecb70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40721b0-e650-4e1b-8c3b-caaf2b8fad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "def function(x):\n",
    "    return (x + 3)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7abdfe-21cf-4e66-8d48-3a1f61028b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x):\n",
    "    return 2 * (x + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65cc5a8-7a9e-4c63-80cb-1fc0ce8ba2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Function\n",
    "def gradient_descent(learning_rate=0.1, max_iterations=50):\n",
    "    x = 2   # starting point\n",
    "    history = []  # to store values for display\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        grad = derivative(x)          # compute gradient\n",
    "        x = x - learning_rate * grad  # update x\n",
    "        cost = function(x)            # calculate new cost\n",
    "\n",
    "        history.append((i, x, cost, grad))\n",
    "\n",
    "        # stopping condition if gradient becomes very small\n",
    "        if abs(grad) < 0.0001:\n",
    "            break\n",
    "\n",
    "    return x, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825bc099-7262-4e79-9212-d67fff784304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Gradient Descent\n",
    "final_x, steps = gradient_descent(learning_rate=0.1, max_iterations=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3305e7c-818b-4209-a6f8-d6ad8d1f49f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent Steps:\n",
      "Iteration 0: x = 1.0000,  Cost = 16.000000, Gradient = 10.000000\n",
      "Iteration 1: x = 0.2000,  Cost = 10.240000, Gradient = 8.000000\n",
      "Iteration 2: x = -0.4400,  Cost = 6.553600, Gradient = 6.400000\n",
      "Iteration 3: x = -0.9520,  Cost = 4.194304, Gradient = 5.120000\n",
      "Iteration 4: x = -1.3616,  Cost = 2.684355, Gradient = 4.096000\n",
      "Iteration 5: x = -1.6893,  Cost = 1.717987, Gradient = 3.276800\n",
      "Iteration 6: x = -1.9514,  Cost = 1.099512, Gradient = 2.621440\n",
      "Iteration 7: x = -2.1611,  Cost = 0.703687, Gradient = 2.097152\n",
      "Iteration 8: x = -2.3289,  Cost = 0.450360, Gradient = 1.677722\n",
      "Iteration 9: x = -2.4631,  Cost = 0.288230, Gradient = 1.342177\n",
      "Iteration 10: x = -2.5705,  Cost = 0.184467, Gradient = 1.073742\n",
      "Iteration 11: x = -2.6564,  Cost = 0.118059, Gradient = 0.858993\n",
      "Iteration 12: x = -2.7251,  Cost = 0.075558, Gradient = 0.687195\n",
      "Iteration 13: x = -2.7801,  Cost = 0.048357, Gradient = 0.549756\n",
      "Iteration 14: x = -2.8241,  Cost = 0.030949, Gradient = 0.439805\n",
      "Iteration 15: x = -2.8593,  Cost = 0.019807, Gradient = 0.351844\n",
      "Iteration 16: x = -2.8874,  Cost = 0.012677, Gradient = 0.281475\n",
      "Iteration 17: x = -2.9099,  Cost = 0.008113, Gradient = 0.225180\n",
      "Iteration 18: x = -2.9279,  Cost = 0.005192, Gradient = 0.180144\n",
      "Iteration 19: x = -2.9424,  Cost = 0.003323, Gradient = 0.144115\n",
      "Iteration 20: x = -2.9539,  Cost = 0.002127, Gradient = 0.115292\n",
      "Iteration 21: x = -2.9631,  Cost = 0.001361, Gradient = 0.092234\n",
      "Iteration 22: x = -2.9705,  Cost = 0.000871, Gradient = 0.073787\n",
      "Iteration 23: x = -2.9764,  Cost = 0.000558, Gradient = 0.059030\n",
      "Iteration 24: x = -2.9811,  Cost = 0.000357, Gradient = 0.047224\n",
      "Iteration 25: x = -2.9849,  Cost = 0.000228, Gradient = 0.037779\n",
      "Iteration 26: x = -2.9879,  Cost = 0.000146, Gradient = 0.030223\n",
      "Iteration 27: x = -2.9903,  Cost = 0.000094, Gradient = 0.024179\n",
      "Iteration 28: x = -2.9923,  Cost = 0.000060, Gradient = 0.019343\n",
      "Iteration 29: x = -2.9938,  Cost = 0.000038, Gradient = 0.015474\n",
      "Iteration 30: x = -2.9950,  Cost = 0.000025, Gradient = 0.012379\n",
      "Iteration 31: x = -2.9960,  Cost = 0.000016, Gradient = 0.009904\n",
      "Iteration 32: x = -2.9968,  Cost = 0.000010, Gradient = 0.007923\n",
      "Iteration 33: x = -2.9975,  Cost = 0.000006, Gradient = 0.006338\n",
      "Iteration 34: x = -2.9980,  Cost = 0.000004, Gradient = 0.005071\n",
      "Iteration 35: x = -2.9984,  Cost = 0.000003, Gradient = 0.004056\n",
      "Iteration 36: x = -2.9987,  Cost = 0.000002, Gradient = 0.003245\n",
      "Iteration 37: x = -2.9990,  Cost = 0.000001, Gradient = 0.002596\n",
      "Iteration 38: x = -2.9992,  Cost = 0.000001, Gradient = 0.002077\n",
      "Iteration 39: x = -2.9993,  Cost = 0.000000, Gradient = 0.001662\n",
      "Iteration 40: x = -2.9995,  Cost = 0.000000, Gradient = 0.001329\n",
      "Iteration 41: x = -2.9996,  Cost = 0.000000, Gradient = 0.001063\n",
      "Iteration 42: x = -2.9997,  Cost = 0.000000, Gradient = 0.000851\n",
      "Iteration 43: x = -2.9997,  Cost = 0.000000, Gradient = 0.000681\n",
      "Iteration 44: x = -2.9998,  Cost = 0.000000, Gradient = 0.000544\n",
      "Iteration 45: x = -2.9998,  Cost = 0.000000, Gradient = 0.000436\n",
      "Iteration 46: x = -2.9999,  Cost = 0.000000, Gradient = 0.000348\n",
      "Iteration 47: x = -2.9999,  Cost = 0.000000, Gradient = 0.000279\n",
      "Iteration 48: x = -2.9999,  Cost = 0.000000, Gradient = 0.000223\n",
      "Iteration 49: x = -2.9999,  Cost = 0.000000, Gradient = 0.000178\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Descent Steps:\")\n",
    "for i, x, cost, grad in steps:\n",
    "    print(f\"Iteration {i}: x = {x:.4f},  Cost = {cost:.6f}, Gradient = {grad:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c47cc54-b618-40b4-b3db-68aa93480514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Local minimum occurs at x = -2.9999\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLocal minimum occurs at x =\", round(final_x, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bdf31-8723-40cb-b1d2-8987c7a0ac24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
